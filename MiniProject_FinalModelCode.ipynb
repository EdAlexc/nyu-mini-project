{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30f04671-0356-41e7-a2c3-ce6c39d5d130",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Deep Learning Mini-Project - Fall 2022\n",
    "#### - by Eduardo Calzadilla\n",
    "#### _New York University - CS-GY 6953 / ECE-GY 7123_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31aaec8-4910-4b16-a853-39eb5d2f5ad0",
   "metadata": {},
   "source": [
    "Starting with the resource found on [kuangliu's GitHub](https://github.com/kuangliu/pytorch-cifar). We tested architectures included as is with 2 training epochs and picked the two with the top test accuracy. For brevity, and computational constraints, we do not conduct all of the training on this notebook but leave the same commented for future recreation of similar accuracy scores. \n",
    "\n",
    "GoogleNet and MobileNetV2 performed the best in terms of accuracy over trainable params in this notebook's iteration, previous accuracy scores (according to the origin repo) and capacity for hyperparameter tuning - excluding other potential strategies such as data augmentation. These were then tested for 25 epochs each on a CPU and GPU runtime, given the Training and Test Accuracy Scores and the CPU and GPU training time in minutes; we selected the GoogleNet structure for the remainder of the study.\n",
    "\n",
    "The structure was then altered to decrease the number of the parameters, as well as increase the testing accuracy. Each new change was ran for 5 epochs and the highest performing structure was kept. Other variables outside of the model's structure were then also experimented with until a high test accuracy was acheieved (>80%).\n",
    "\n",
    "The final architecture is shown at the end of the notebook and the results of the tests are summarized in the figures on the Report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0f88a32-230f-4649-b5f8-9969b5fb6052",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.13.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: setuptools in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.5.1)\n",
      "Requirement already satisfied: wheel in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchvision in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (0.14.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchvision) (9.3.0)\n",
      "Requirement already satisfied: numpy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: requests in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchvision) (4.4.0)\n",
      "Requirement already satisfied: torch==1.13.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchvision) (1.13.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch==1.13.0->torchvision) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch==1.13.0->torchvision) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch==1.13.0->torchvision) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch==1.13.0->torchvision) (8.5.0.96)\n",
      "Requirement already satisfied: setuptools in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchvision) (65.5.1)\n",
      "Requirement already satisfied: wheel in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchvision) (0.38.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (1.26.13)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-math in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (0.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch-summary in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n",
    "%pip install torchvision\n",
    "%pip install python-math\n",
    "%pip install torch-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bde79127-ee86-4a35-b805-0c825925c70c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/studio-lab-user/gitFolder'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import system related libraries\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# establish path\n",
    "module_path = \"gitFolder\"\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2ea267a-d5e2-45ea-8287-469f5e73acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing relevant torch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchsummary import summary\n",
    "\n",
    "# torchvision libraries\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#data prep and math libraries\n",
    "import argparse\n",
    "import math\n",
    "import time\n",
    "\n",
    "# import local libraries\n",
    "from models import * # models defined according to https://github.com/kuangliu/pytorch-cifar\n",
    "from utils import progress_bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7ee0d53-f1e8-41ae-8d93-0f419067fafe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Data prep\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff972de5-a6dd-4269-a649-231de2cffe6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model...\n",
      "\t ==> Model sent to cpu...\n",
      "\t ==> Model sent to cpu...\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# send to device, and match with parallel connection\n",
    "def send_to_device(net):\n",
    "    net = net.to(device)\n",
    "    if device == 'cuda':\n",
    "        net = torch.nn.DataParallel(net)\n",
    "        cudnn.benchmark = True\n",
    "        print('\\t ==> Model sent to gpu...')\n",
    "    else:\n",
    "        print('\\t ==> Model sent to cpu...')\n",
    "        \n",
    "    return net\n",
    "\n",
    "\n",
    "print('==> Building model...')\n",
    "# Res_net18 = ResNet18()\n",
    "Google_net = GoogLeNet()\n",
    "Google_net5 = GoogLeNet5()\n",
    "# Dense_net = DenseNet121()\n",
    "# Mobile_net = MobileNet()\n",
    "# Mobile_netV2 = MobileNetV2()\n",
    "# SEN_net18 = SENet18()\n",
    "# simple_DLA = SimpleDLA()\n",
    "\n",
    "\n",
    "# Res_net18 = send_to_device(Res_net18)\n",
    "Google_net = send_to_device(Google_net)\n",
    "Google_net5 = send_to_device(Google_net5)\n",
    "# Dense_net = send_to_device(Dense_net)\n",
    "# Mobile_net = send_to_device(Mobile_net)\n",
    "# Mobile_netV2 = send_to_device(Mobile_netV2)\n",
    "# SEN_net18 = send_to_device(SEN_net18)\n",
    "# simple_DLA = send_to_device(simple_DLA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e45746a-acc5-41a1-826a-de1f2d615608",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters:  3799530\n"
     ]
    }
   ],
   "source": [
    "# number of parameters in selected model\n",
    "print('Number of trainable parameters: ', sum(p.numel() for p in Google_net5.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9de574b1-112d-49f6-ad1e-e0a7f24a58de",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 96, 30, 30]          --\n",
      "|    └─Conv2d: 2-1                       [-1, 96, 30, 30]          7,296\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 96, 30, 30]          192\n",
      "|    └─ReLU: 2-3                         [-1, 96, 30, 30]          --\n",
      "├─Inception: 1-2                         [-1, 128, 30, 30]         --\n",
      "|    └─Sequential: 2-4                   [-1, 32, 30, 30]          --\n",
      "|    |    └─Conv2d: 3-1                  [-1, 32, 30, 30]          3,104\n",
      "|    |    └─BatchNorm2d: 3-2             [-1, 32, 30, 30]          64\n",
      "|    |    └─ReLU: 3-3                    [-1, 32, 30, 30]          --\n",
      "|    └─Sequential: 2-5                   [-1, 64, 30, 30]          --\n",
      "|    |    └─Conv2d: 3-4                  [-1, 48, 30, 30]          4,656\n",
      "|    |    └─BatchNorm2d: 3-5             [-1, 48, 30, 30]          96\n",
      "|    |    └─ReLU: 3-6                    [-1, 48, 30, 30]          --\n",
      "|    |    └─Conv2d: 3-7                  [-1, 64, 30, 30]          76,864\n",
      "|    |    └─BatchNorm2d: 3-8             [-1, 64, 30, 30]          128\n",
      "|    |    └─ReLU: 3-9                    [-1, 64, 30, 30]          --\n",
      "|    └─Sequential: 2-6                   [-1, 16, 30, 30]          --\n",
      "|    |    └─Conv2d: 3-10                 [-1, 8, 30, 30]           776\n",
      "|    |    └─BatchNorm2d: 3-11            [-1, 8, 30, 30]           16\n",
      "|    |    └─ReLU: 3-12                   [-1, 8, 30, 30]           --\n",
      "|    |    └─Conv2d: 3-13                 [-1, 16, 30, 30]          3,216\n",
      "|    |    └─BatchNorm2d: 3-14            [-1, 16, 30, 30]          32\n",
      "|    |    └─ReLU: 3-15                   [-1, 16, 30, 30]          --\n",
      "|    |    └─Conv2d: 3-16                 [-1, 16, 30, 30]          6,416\n",
      "|    |    └─BatchNorm2d: 3-17            [-1, 16, 30, 30]          32\n",
      "|    |    └─ReLU: 3-18                   [-1, 16, 30, 30]          --\n",
      "|    └─Sequential: 2-7                   [-1, 16, 30, 30]          --\n",
      "|    |    └─MaxPool2d: 3-19              [-1, 96, 30, 30]          --\n",
      "|    |    └─Conv2d: 3-20                 [-1, 16, 30, 30]          1,552\n",
      "|    |    └─BatchNorm2d: 3-21            [-1, 16, 30, 30]          32\n",
      "|    |    └─ReLU: 3-22                   [-1, 16, 30, 30]          --\n",
      "├─Inception: 1-3                         [-1, 240, 30, 30]         --\n",
      "|    └─Sequential: 2-8                   [-1, 64, 30, 30]          --\n",
      "|    |    └─Conv2d: 3-23                 [-1, 64, 30, 30]          8,256\n",
      "|    |    └─BatchNorm2d: 3-24            [-1, 64, 30, 30]          128\n",
      "|    |    └─ReLU: 3-25                   [-1, 64, 30, 30]          --\n",
      "|    └─Sequential: 2-9                   [-1, 96, 30, 30]          --\n",
      "|    |    └─Conv2d: 3-26                 [-1, 64, 30, 30]          8,256\n",
      "|    |    └─BatchNorm2d: 3-27            [-1, 64, 30, 30]          128\n",
      "|    |    └─ReLU: 3-28                   [-1, 64, 30, 30]          --\n",
      "|    |    └─Conv2d: 3-29                 [-1, 96, 30, 30]          153,696\n",
      "|    |    └─BatchNorm2d: 3-30            [-1, 96, 30, 30]          192\n",
      "|    |    └─ReLU: 3-31                   [-1, 96, 30, 30]          --\n",
      "|    └─Sequential: 2-10                  [-1, 48, 30, 30]          --\n",
      "|    |    └─Conv2d: 3-32                 [-1, 16, 30, 30]          2,064\n",
      "|    |    └─BatchNorm2d: 3-33            [-1, 16, 30, 30]          32\n",
      "|    |    └─ReLU: 3-34                   [-1, 16, 30, 30]          --\n",
      "|    |    └─Conv2d: 3-35                 [-1, 48, 30, 30]          19,248\n",
      "|    |    └─BatchNorm2d: 3-36            [-1, 48, 30, 30]          96\n",
      "|    |    └─ReLU: 3-37                   [-1, 48, 30, 30]          --\n",
      "|    |    └─Conv2d: 3-38                 [-1, 48, 30, 30]          57,648\n",
      "|    |    └─BatchNorm2d: 3-39            [-1, 48, 30, 30]          96\n",
      "|    |    └─ReLU: 3-40                   [-1, 48, 30, 30]          --\n",
      "|    └─Sequential: 2-11                  [-1, 32, 30, 30]          --\n",
      "|    |    └─MaxPool2d: 3-41              [-1, 128, 30, 30]         --\n",
      "|    |    └─Conv2d: 3-42                 [-1, 32, 30, 30]          4,128\n",
      "|    |    └─BatchNorm2d: 3-43            [-1, 32, 30, 30]          64\n",
      "|    |    └─ReLU: 3-44                   [-1, 32, 30, 30]          --\n",
      "├─MaxPool2d: 1-4                         [-1, 240, 14, 14]         --\n",
      "├─Inception: 1-5                         [-1, 512, 14, 14]         --\n",
      "|    └─Sequential: 2-12                  [-1, 192, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-45                 [-1, 192, 14, 14]         46,272\n",
      "|    |    └─BatchNorm2d: 3-46            [-1, 192, 14, 14]         384\n",
      "|    |    └─ReLU: 3-47                   [-1, 192, 14, 14]         --\n",
      "|    └─Sequential: 2-13                  [-1, 208, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-48                 [-1, 96, 14, 14]          23,136\n",
      "|    |    └─BatchNorm2d: 3-49            [-1, 96, 14, 14]          192\n",
      "|    |    └─ReLU: 3-50                   [-1, 96, 14, 14]          --\n",
      "|    |    └─Conv2d: 3-51                 [-1, 208, 14, 14]         499,408\n",
      "|    |    └─BatchNorm2d: 3-52            [-1, 208, 14, 14]         416\n",
      "|    |    └─ReLU: 3-53                   [-1, 208, 14, 14]         --\n",
      "|    └─Sequential: 2-14                  [-1, 48, 14, 14]          --\n",
      "|    |    └─Conv2d: 3-54                 [-1, 16, 14, 14]          3,856\n",
      "|    |    └─BatchNorm2d: 3-55            [-1, 16, 14, 14]          32\n",
      "|    |    └─ReLU: 3-56                   [-1, 16, 14, 14]          --\n",
      "|    |    └─Conv2d: 3-57                 [-1, 48, 14, 14]          19,248\n",
      "|    |    └─BatchNorm2d: 3-58            [-1, 48, 14, 14]          96\n",
      "|    |    └─ReLU: 3-59                   [-1, 48, 14, 14]          --\n",
      "|    |    └─Conv2d: 3-60                 [-1, 48, 14, 14]          57,648\n",
      "|    |    └─BatchNorm2d: 3-61            [-1, 48, 14, 14]          96\n",
      "|    |    └─ReLU: 3-62                   [-1, 48, 14, 14]          --\n",
      "|    └─Sequential: 2-15                  [-1, 64, 14, 14]          --\n",
      "|    |    └─MaxPool2d: 3-63              [-1, 240, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-64                 [-1, 64, 14, 14]          15,424\n",
      "|    |    └─BatchNorm2d: 3-65            [-1, 64, 14, 14]          128\n",
      "|    |    └─ReLU: 3-66                   [-1, 64, 14, 14]          --\n",
      "├─Inception: 1-6                         [-1, 256, 14, 14]         --\n",
      "|    └─Sequential: 2-16                  [-1, 80, 14, 14]          --\n",
      "|    |    └─Conv2d: 3-67                 [-1, 80, 14, 14]          41,040\n",
      "|    |    └─BatchNorm2d: 3-68            [-1, 80, 14, 14]          160\n",
      "|    |    └─ReLU: 3-69                   [-1, 80, 14, 14]          --\n",
      "|    └─Sequential: 2-17                  [-1, 112, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-70                 [-1, 56, 14, 14]          28,728\n",
      "|    |    └─BatchNorm2d: 3-71            [-1, 56, 14, 14]          112\n",
      "|    |    └─ReLU: 3-72                   [-1, 56, 14, 14]          --\n",
      "|    |    └─Conv2d: 3-73                 [-1, 112, 14, 14]         156,912\n",
      "|    |    └─BatchNorm2d: 3-74            [-1, 112, 14, 14]         224\n",
      "|    |    └─ReLU: 3-75                   [-1, 112, 14, 14]         --\n",
      "|    └─Sequential: 2-18                  [-1, 32, 14, 14]          --\n",
      "|    |    └─Conv2d: 3-76                 [-1, 12, 14, 14]          6,156\n",
      "|    |    └─BatchNorm2d: 3-77            [-1, 12, 14, 14]          24\n",
      "|    |    └─ReLU: 3-78                   [-1, 12, 14, 14]          --\n",
      "|    |    └─Conv2d: 3-79                 [-1, 32, 14, 14]          9,632\n",
      "|    |    └─BatchNorm2d: 3-80            [-1, 32, 14, 14]          64\n",
      "|    |    └─ReLU: 3-81                   [-1, 32, 14, 14]          --\n",
      "|    |    └─Conv2d: 3-82                 [-1, 32, 14, 14]          25,632\n",
      "|    |    └─BatchNorm2d: 3-83            [-1, 32, 14, 14]          64\n",
      "|    |    └─ReLU: 3-84                   [-1, 32, 14, 14]          --\n",
      "|    └─Sequential: 2-19                  [-1, 32, 14, 14]          --\n",
      "|    |    └─MaxPool2d: 3-85              [-1, 512, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-86                 [-1, 32, 14, 14]          16,416\n",
      "|    |    └─BatchNorm2d: 3-87            [-1, 32, 14, 14]          64\n",
      "|    |    └─ReLU: 3-88                   [-1, 32, 14, 14]          --\n",
      "├─Inception: 1-7                         [-1, 256, 14, 14]         --\n",
      "|    └─Sequential: 2-20                  [-1, 64, 14, 14]          --\n",
      "|    |    └─Conv2d: 3-89                 [-1, 64, 14, 14]          16,448\n",
      "|    |    └─BatchNorm2d: 3-90            [-1, 64, 14, 14]          128\n",
      "|    |    └─ReLU: 3-91                   [-1, 64, 14, 14]          --\n",
      "|    └─Sequential: 2-21                  [-1, 128, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-92                 [-1, 64, 14, 14]          16,448\n",
      "|    |    └─BatchNorm2d: 3-93            [-1, 64, 14, 14]          128\n",
      "|    |    └─ReLU: 3-94                   [-1, 64, 14, 14]          --\n",
      "|    |    └─Conv2d: 3-95                 [-1, 128, 14, 14]         204,928\n",
      "|    |    └─BatchNorm2d: 3-96            [-1, 128, 14, 14]         256\n",
      "|    |    └─ReLU: 3-97                   [-1, 128, 14, 14]         --\n",
      "|    └─Sequential: 2-22                  [-1, 32, 14, 14]          --\n",
      "|    |    └─Conv2d: 3-98                 [-1, 12, 14, 14]          3,084\n",
      "|    |    └─BatchNorm2d: 3-99            [-1, 12, 14, 14]          24\n",
      "|    |    └─ReLU: 3-100                  [-1, 12, 14, 14]          --\n",
      "|    |    └─Conv2d: 3-101                [-1, 32, 14, 14]          9,632\n",
      "|    |    └─BatchNorm2d: 3-102           [-1, 32, 14, 14]          64\n",
      "|    |    └─ReLU: 3-103                  [-1, 32, 14, 14]          --\n",
      "|    |    └─Conv2d: 3-104                [-1, 32, 14, 14]          25,632\n",
      "|    |    └─BatchNorm2d: 3-105           [-1, 32, 14, 14]          64\n",
      "|    |    └─ReLU: 3-106                  [-1, 32, 14, 14]          --\n",
      "|    └─Sequential: 2-23                  [-1, 32, 14, 14]          --\n",
      "|    |    └─MaxPool2d: 3-107             [-1, 256, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-108                [-1, 32, 14, 14]          8,224\n",
      "|    |    └─BatchNorm2d: 3-109           [-1, 32, 14, 14]          64\n",
      "|    |    └─ReLU: 3-110                  [-1, 32, 14, 14]          --\n",
      "├─Inception: 1-8                         [-1, 264, 14, 14]         --\n",
      "|    └─Sequential: 2-24                  [-1, 56, 14, 14]          --\n",
      "|    |    └─Conv2d: 3-111                [-1, 56, 14, 14]          14,392\n",
      "|    |    └─BatchNorm2d: 3-112           [-1, 56, 14, 14]          112\n",
      "|    |    └─ReLU: 3-113                  [-1, 56, 14, 14]          --\n",
      "|    └─Sequential: 2-25                  [-1, 144, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-114                [-1, 72, 14, 14]          18,504\n",
      "|    |    └─BatchNorm2d: 3-115           [-1, 72, 14, 14]          144\n",
      "|    |    └─ReLU: 3-116                  [-1, 72, 14, 14]          --\n",
      "|    |    └─Conv2d: 3-117                [-1, 144, 14, 14]         259,344\n",
      "|    |    └─BatchNorm2d: 3-118           [-1, 144, 14, 14]         288\n",
      "|    |    └─ReLU: 3-119                  [-1, 144, 14, 14]         --\n",
      "|    └─Sequential: 2-26                  [-1, 32, 14, 14]          --\n",
      "|    |    └─Conv2d: 3-120                [-1, 16, 14, 14]          4,112\n",
      "|    |    └─BatchNorm2d: 3-121           [-1, 16, 14, 14]          32\n",
      "|    |    └─ReLU: 3-122                  [-1, 16, 14, 14]          --\n",
      "|    |    └─Conv2d: 3-123                [-1, 32, 14, 14]          12,832\n",
      "|    |    └─BatchNorm2d: 3-124           [-1, 32, 14, 14]          64\n",
      "|    |    └─ReLU: 3-125                  [-1, 32, 14, 14]          --\n",
      "|    |    └─Conv2d: 3-126                [-1, 32, 14, 14]          25,632\n",
      "|    |    └─BatchNorm2d: 3-127           [-1, 32, 14, 14]          64\n",
      "|    |    └─ReLU: 3-128                  [-1, 32, 14, 14]          --\n",
      "|    └─Sequential: 2-27                  [-1, 32, 14, 14]          --\n",
      "|    |    └─MaxPool2d: 3-129             [-1, 256, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-130                [-1, 32, 14, 14]          8,224\n",
      "|    |    └─BatchNorm2d: 3-131           [-1, 32, 14, 14]          64\n",
      "|    |    └─ReLU: 3-132                  [-1, 32, 14, 14]          --\n",
      "├─Inception: 1-9                         [-1, 416, 14, 14]         --\n",
      "|    └─Sequential: 2-28                  [-1, 128, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-133                [-1, 128, 14, 14]         33,920\n",
      "|    |    └─BatchNorm2d: 3-134           [-1, 128, 14, 14]         256\n",
      "|    |    └─ReLU: 3-135                  [-1, 128, 14, 14]         --\n",
      "|    └─Sequential: 2-29                  [-1, 160, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-136                [-1, 80, 14, 14]          21,200\n",
      "|    |    └─BatchNorm2d: 3-137           [-1, 80, 14, 14]          160\n",
      "|    |    └─ReLU: 3-138                  [-1, 80, 14, 14]          --\n",
      "|    |    └─Conv2d: 3-139                [-1, 160, 14, 14]         320,160\n",
      "|    |    └─BatchNorm2d: 3-140           [-1, 160, 14, 14]         320\n",
      "|    |    └─ReLU: 3-141                  [-1, 160, 14, 14]         --\n",
      "|    └─Sequential: 2-30                  [-1, 64, 14, 14]          --\n",
      "|    |    └─Conv2d: 3-142                [-1, 16, 14, 14]          4,240\n",
      "|    |    └─BatchNorm2d: 3-143           [-1, 16, 14, 14]          32\n",
      "|    |    └─ReLU: 3-144                  [-1, 16, 14, 14]          --\n",
      "|    |    └─Conv2d: 3-145                [-1, 64, 14, 14]          25,664\n",
      "|    |    └─BatchNorm2d: 3-146           [-1, 64, 14, 14]          128\n",
      "|    |    └─ReLU: 3-147                  [-1, 64, 14, 14]          --\n",
      "|    |    └─Conv2d: 3-148                [-1, 64, 14, 14]          102,464\n",
      "|    |    └─BatchNorm2d: 3-149           [-1, 64, 14, 14]          128\n",
      "|    |    └─ReLU: 3-150                  [-1, 64, 14, 14]          --\n",
      "|    └─Sequential: 2-31                  [-1, 64, 14, 14]          --\n",
      "|    |    └─MaxPool2d: 3-151             [-1, 264, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-152                [-1, 64, 14, 14]          16,960\n",
      "|    |    └─BatchNorm2d: 3-153           [-1, 64, 14, 14]          128\n",
      "|    |    └─ReLU: 3-154                  [-1, 64, 14, 14]          --\n",
      "├─MaxPool2d: 1-10                        [-1, 416, 6, 6]           --\n",
      "├─Inception: 1-11                        [-1, 416, 6, 6]           --\n",
      "|    └─Sequential: 2-32                  [-1, 128, 6, 6]           --\n",
      "|    |    └─Conv2d: 3-155                [-1, 128, 6, 6]           53,376\n",
      "|    |    └─BatchNorm2d: 3-156           [-1, 128, 6, 6]           256\n",
      "|    |    └─ReLU: 3-157                  [-1, 128, 6, 6]           --\n",
      "|    └─Sequential: 2-33                  [-1, 160, 6, 6]           --\n",
      "|    |    └─Conv2d: 3-158                [-1, 80, 6, 6]            33,360\n",
      "|    |    └─BatchNorm2d: 3-159           [-1, 80, 6, 6]            160\n",
      "|    |    └─ReLU: 3-160                  [-1, 80, 6, 6]            --\n",
      "|    |    └─Conv2d: 3-161                [-1, 160, 6, 6]           320,160\n",
      "|    |    └─BatchNorm2d: 3-162           [-1, 160, 6, 6]           320\n",
      "|    |    └─ReLU: 3-163                  [-1, 160, 6, 6]           --\n",
      "|    └─Sequential: 2-34                  [-1, 64, 6, 6]            --\n",
      "|    |    └─Conv2d: 3-164                [-1, 16, 6, 6]            6,672\n",
      "|    |    └─BatchNorm2d: 3-165           [-1, 16, 6, 6]            32\n",
      "|    |    └─ReLU: 3-166                  [-1, 16, 6, 6]            --\n",
      "|    |    └─Conv2d: 3-167                [-1, 64, 6, 6]            25,664\n",
      "|    |    └─BatchNorm2d: 3-168           [-1, 64, 6, 6]            128\n",
      "|    |    └─ReLU: 3-169                  [-1, 64, 6, 6]            --\n",
      "|    |    └─Conv2d: 3-170                [-1, 64, 6, 6]            102,464\n",
      "|    |    └─BatchNorm2d: 3-171           [-1, 64, 6, 6]            128\n",
      "|    |    └─ReLU: 3-172                  [-1, 64, 6, 6]            --\n",
      "|    └─Sequential: 2-35                  [-1, 64, 6, 6]            --\n",
      "|    |    └─MaxPool2d: 3-173             [-1, 416, 6, 6]           --\n",
      "|    |    └─Conv2d: 3-174                [-1, 64, 6, 6]            26,688\n",
      "|    |    └─BatchNorm2d: 3-175           [-1, 64, 6, 6]            128\n",
      "|    |    └─ReLU: 3-176                  [-1, 64, 6, 6]            --\n",
      "├─Inception: 1-12                        [-1, 512, 6, 6]           --\n",
      "|    └─Sequential: 2-36                  [-1, 192, 6, 6]           --\n",
      "|    |    └─Conv2d: 3-177                [-1, 192, 6, 6]           80,064\n",
      "|    |    └─BatchNorm2d: 3-178           [-1, 192, 6, 6]           384\n",
      "|    |    └─ReLU: 3-179                  [-1, 192, 6, 6]           --\n",
      "|    └─Sequential: 2-37                  [-1, 192, 6, 6]           --\n",
      "|    |    └─Conv2d: 3-180                [-1, 96, 6, 6]            40,032\n",
      "|    |    └─BatchNorm2d: 3-181           [-1, 96, 6, 6]            192\n",
      "|    |    └─ReLU: 3-182                  [-1, 96, 6, 6]            --\n",
      "|    |    └─Conv2d: 3-183                [-1, 192, 6, 6]           460,992\n",
      "|    |    └─BatchNorm2d: 3-184           [-1, 192, 6, 6]           384\n",
      "|    |    └─ReLU: 3-185                  [-1, 192, 6, 6]           --\n",
      "|    └─Sequential: 2-38                  [-1, 64, 6, 6]            --\n",
      "|    |    └─Conv2d: 3-186                [-1, 24, 6, 6]            10,008\n",
      "|    |    └─BatchNorm2d: 3-187           [-1, 24, 6, 6]            48\n",
      "|    |    └─ReLU: 3-188                  [-1, 24, 6, 6]            --\n",
      "|    |    └─Conv2d: 3-189                [-1, 64, 6, 6]            38,464\n",
      "|    |    └─BatchNorm2d: 3-190           [-1, 64, 6, 6]            128\n",
      "|    |    └─ReLU: 3-191                  [-1, 64, 6, 6]            --\n",
      "|    |    └─Conv2d: 3-192                [-1, 64, 6, 6]            102,464\n",
      "|    |    └─BatchNorm2d: 3-193           [-1, 64, 6, 6]            128\n",
      "|    |    └─ReLU: 3-194                  [-1, 64, 6, 6]            --\n",
      "|    └─Sequential: 2-39                  [-1, 64, 6, 6]            --\n",
      "|    |    └─MaxPool2d: 3-195             [-1, 416, 6, 6]           --\n",
      "|    |    └─Conv2d: 3-196                [-1, 64, 6, 6]            26,688\n",
      "|    |    └─BatchNorm2d: 3-197           [-1, 64, 6, 6]            128\n",
      "|    |    └─ReLU: 3-198                  [-1, 64, 6, 6]            --\n",
      "├─AvgPool2d: 1-13                        [-1, 512, 1, 1]           --\n",
      "├─Linear: 1-14                           [-1, 10]                  5,130\n",
      "==========================================================================================\n",
      "Total params: 3,799,530\n",
      "Trainable params: 3,799,530\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 787.61\n",
      "==========================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 16.85\n",
      "Params size (MB): 14.49\n",
      "Estimated Total Size (MB): 31.36\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 96, 30, 30]          --\n",
       "|    └─Conv2d: 2-1                       [-1, 96, 30, 30]          7,296\n",
       "|    └─BatchNorm2d: 2-2                  [-1, 96, 30, 30]          192\n",
       "|    └─ReLU: 2-3                         [-1, 96, 30, 30]          --\n",
       "├─Inception: 1-2                         [-1, 128, 30, 30]         --\n",
       "|    └─Sequential: 2-4                   [-1, 32, 30, 30]          --\n",
       "|    |    └─Conv2d: 3-1                  [-1, 32, 30, 30]          3,104\n",
       "|    |    └─BatchNorm2d: 3-2             [-1, 32, 30, 30]          64\n",
       "|    |    └─ReLU: 3-3                    [-1, 32, 30, 30]          --\n",
       "|    └─Sequential: 2-5                   [-1, 64, 30, 30]          --\n",
       "|    |    └─Conv2d: 3-4                  [-1, 48, 30, 30]          4,656\n",
       "|    |    └─BatchNorm2d: 3-5             [-1, 48, 30, 30]          96\n",
       "|    |    └─ReLU: 3-6                    [-1, 48, 30, 30]          --\n",
       "|    |    └─Conv2d: 3-7                  [-1, 64, 30, 30]          76,864\n",
       "|    |    └─BatchNorm2d: 3-8             [-1, 64, 30, 30]          128\n",
       "|    |    └─ReLU: 3-9                    [-1, 64, 30, 30]          --\n",
       "|    └─Sequential: 2-6                   [-1, 16, 30, 30]          --\n",
       "|    |    └─Conv2d: 3-10                 [-1, 8, 30, 30]           776\n",
       "|    |    └─BatchNorm2d: 3-11            [-1, 8, 30, 30]           16\n",
       "|    |    └─ReLU: 3-12                   [-1, 8, 30, 30]           --\n",
       "|    |    └─Conv2d: 3-13                 [-1, 16, 30, 30]          3,216\n",
       "|    |    └─BatchNorm2d: 3-14            [-1, 16, 30, 30]          32\n",
       "|    |    └─ReLU: 3-15                   [-1, 16, 30, 30]          --\n",
       "|    |    └─Conv2d: 3-16                 [-1, 16, 30, 30]          6,416\n",
       "|    |    └─BatchNorm2d: 3-17            [-1, 16, 30, 30]          32\n",
       "|    |    └─ReLU: 3-18                   [-1, 16, 30, 30]          --\n",
       "|    └─Sequential: 2-7                   [-1, 16, 30, 30]          --\n",
       "|    |    └─MaxPool2d: 3-19              [-1, 96, 30, 30]          --\n",
       "|    |    └─Conv2d: 3-20                 [-1, 16, 30, 30]          1,552\n",
       "|    |    └─BatchNorm2d: 3-21            [-1, 16, 30, 30]          32\n",
       "|    |    └─ReLU: 3-22                   [-1, 16, 30, 30]          --\n",
       "├─Inception: 1-3                         [-1, 240, 30, 30]         --\n",
       "|    └─Sequential: 2-8                   [-1, 64, 30, 30]          --\n",
       "|    |    └─Conv2d: 3-23                 [-1, 64, 30, 30]          8,256\n",
       "|    |    └─BatchNorm2d: 3-24            [-1, 64, 30, 30]          128\n",
       "|    |    └─ReLU: 3-25                   [-1, 64, 30, 30]          --\n",
       "|    └─Sequential: 2-9                   [-1, 96, 30, 30]          --\n",
       "|    |    └─Conv2d: 3-26                 [-1, 64, 30, 30]          8,256\n",
       "|    |    └─BatchNorm2d: 3-27            [-1, 64, 30, 30]          128\n",
       "|    |    └─ReLU: 3-28                   [-1, 64, 30, 30]          --\n",
       "|    |    └─Conv2d: 3-29                 [-1, 96, 30, 30]          153,696\n",
       "|    |    └─BatchNorm2d: 3-30            [-1, 96, 30, 30]          192\n",
       "|    |    └─ReLU: 3-31                   [-1, 96, 30, 30]          --\n",
       "|    └─Sequential: 2-10                  [-1, 48, 30, 30]          --\n",
       "|    |    └─Conv2d: 3-32                 [-1, 16, 30, 30]          2,064\n",
       "|    |    └─BatchNorm2d: 3-33            [-1, 16, 30, 30]          32\n",
       "|    |    └─ReLU: 3-34                   [-1, 16, 30, 30]          --\n",
       "|    |    └─Conv2d: 3-35                 [-1, 48, 30, 30]          19,248\n",
       "|    |    └─BatchNorm2d: 3-36            [-1, 48, 30, 30]          96\n",
       "|    |    └─ReLU: 3-37                   [-1, 48, 30, 30]          --\n",
       "|    |    └─Conv2d: 3-38                 [-1, 48, 30, 30]          57,648\n",
       "|    |    └─BatchNorm2d: 3-39            [-1, 48, 30, 30]          96\n",
       "|    |    └─ReLU: 3-40                   [-1, 48, 30, 30]          --\n",
       "|    └─Sequential: 2-11                  [-1, 32, 30, 30]          --\n",
       "|    |    └─MaxPool2d: 3-41              [-1, 128, 30, 30]         --\n",
       "|    |    └─Conv2d: 3-42                 [-1, 32, 30, 30]          4,128\n",
       "|    |    └─BatchNorm2d: 3-43            [-1, 32, 30, 30]          64\n",
       "|    |    └─ReLU: 3-44                   [-1, 32, 30, 30]          --\n",
       "├─MaxPool2d: 1-4                         [-1, 240, 14, 14]         --\n",
       "├─Inception: 1-5                         [-1, 512, 14, 14]         --\n",
       "|    └─Sequential: 2-12                  [-1, 192, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-45                 [-1, 192, 14, 14]         46,272\n",
       "|    |    └─BatchNorm2d: 3-46            [-1, 192, 14, 14]         384\n",
       "|    |    └─ReLU: 3-47                   [-1, 192, 14, 14]         --\n",
       "|    └─Sequential: 2-13                  [-1, 208, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-48                 [-1, 96, 14, 14]          23,136\n",
       "|    |    └─BatchNorm2d: 3-49            [-1, 96, 14, 14]          192\n",
       "|    |    └─ReLU: 3-50                   [-1, 96, 14, 14]          --\n",
       "|    |    └─Conv2d: 3-51                 [-1, 208, 14, 14]         499,408\n",
       "|    |    └─BatchNorm2d: 3-52            [-1, 208, 14, 14]         416\n",
       "|    |    └─ReLU: 3-53                   [-1, 208, 14, 14]         --\n",
       "|    └─Sequential: 2-14                  [-1, 48, 14, 14]          --\n",
       "|    |    └─Conv2d: 3-54                 [-1, 16, 14, 14]          3,856\n",
       "|    |    └─BatchNorm2d: 3-55            [-1, 16, 14, 14]          32\n",
       "|    |    └─ReLU: 3-56                   [-1, 16, 14, 14]          --\n",
       "|    |    └─Conv2d: 3-57                 [-1, 48, 14, 14]          19,248\n",
       "|    |    └─BatchNorm2d: 3-58            [-1, 48, 14, 14]          96\n",
       "|    |    └─ReLU: 3-59                   [-1, 48, 14, 14]          --\n",
       "|    |    └─Conv2d: 3-60                 [-1, 48, 14, 14]          57,648\n",
       "|    |    └─BatchNorm2d: 3-61            [-1, 48, 14, 14]          96\n",
       "|    |    └─ReLU: 3-62                   [-1, 48, 14, 14]          --\n",
       "|    └─Sequential: 2-15                  [-1, 64, 14, 14]          --\n",
       "|    |    └─MaxPool2d: 3-63              [-1, 240, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-64                 [-1, 64, 14, 14]          15,424\n",
       "|    |    └─BatchNorm2d: 3-65            [-1, 64, 14, 14]          128\n",
       "|    |    └─ReLU: 3-66                   [-1, 64, 14, 14]          --\n",
       "├─Inception: 1-6                         [-1, 256, 14, 14]         --\n",
       "|    └─Sequential: 2-16                  [-1, 80, 14, 14]          --\n",
       "|    |    └─Conv2d: 3-67                 [-1, 80, 14, 14]          41,040\n",
       "|    |    └─BatchNorm2d: 3-68            [-1, 80, 14, 14]          160\n",
       "|    |    └─ReLU: 3-69                   [-1, 80, 14, 14]          --\n",
       "|    └─Sequential: 2-17                  [-1, 112, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-70                 [-1, 56, 14, 14]          28,728\n",
       "|    |    └─BatchNorm2d: 3-71            [-1, 56, 14, 14]          112\n",
       "|    |    └─ReLU: 3-72                   [-1, 56, 14, 14]          --\n",
       "|    |    └─Conv2d: 3-73                 [-1, 112, 14, 14]         156,912\n",
       "|    |    └─BatchNorm2d: 3-74            [-1, 112, 14, 14]         224\n",
       "|    |    └─ReLU: 3-75                   [-1, 112, 14, 14]         --\n",
       "|    └─Sequential: 2-18                  [-1, 32, 14, 14]          --\n",
       "|    |    └─Conv2d: 3-76                 [-1, 12, 14, 14]          6,156\n",
       "|    |    └─BatchNorm2d: 3-77            [-1, 12, 14, 14]          24\n",
       "|    |    └─ReLU: 3-78                   [-1, 12, 14, 14]          --\n",
       "|    |    └─Conv2d: 3-79                 [-1, 32, 14, 14]          9,632\n",
       "|    |    └─BatchNorm2d: 3-80            [-1, 32, 14, 14]          64\n",
       "|    |    └─ReLU: 3-81                   [-1, 32, 14, 14]          --\n",
       "|    |    └─Conv2d: 3-82                 [-1, 32, 14, 14]          25,632\n",
       "|    |    └─BatchNorm2d: 3-83            [-1, 32, 14, 14]          64\n",
       "|    |    └─ReLU: 3-84                   [-1, 32, 14, 14]          --\n",
       "|    └─Sequential: 2-19                  [-1, 32, 14, 14]          --\n",
       "|    |    └─MaxPool2d: 3-85              [-1, 512, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-86                 [-1, 32, 14, 14]          16,416\n",
       "|    |    └─BatchNorm2d: 3-87            [-1, 32, 14, 14]          64\n",
       "|    |    └─ReLU: 3-88                   [-1, 32, 14, 14]          --\n",
       "├─Inception: 1-7                         [-1, 256, 14, 14]         --\n",
       "|    └─Sequential: 2-20                  [-1, 64, 14, 14]          --\n",
       "|    |    └─Conv2d: 3-89                 [-1, 64, 14, 14]          16,448\n",
       "|    |    └─BatchNorm2d: 3-90            [-1, 64, 14, 14]          128\n",
       "|    |    └─ReLU: 3-91                   [-1, 64, 14, 14]          --\n",
       "|    └─Sequential: 2-21                  [-1, 128, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-92                 [-1, 64, 14, 14]          16,448\n",
       "|    |    └─BatchNorm2d: 3-93            [-1, 64, 14, 14]          128\n",
       "|    |    └─ReLU: 3-94                   [-1, 64, 14, 14]          --\n",
       "|    |    └─Conv2d: 3-95                 [-1, 128, 14, 14]         204,928\n",
       "|    |    └─BatchNorm2d: 3-96            [-1, 128, 14, 14]         256\n",
       "|    |    └─ReLU: 3-97                   [-1, 128, 14, 14]         --\n",
       "|    └─Sequential: 2-22                  [-1, 32, 14, 14]          --\n",
       "|    |    └─Conv2d: 3-98                 [-1, 12, 14, 14]          3,084\n",
       "|    |    └─BatchNorm2d: 3-99            [-1, 12, 14, 14]          24\n",
       "|    |    └─ReLU: 3-100                  [-1, 12, 14, 14]          --\n",
       "|    |    └─Conv2d: 3-101                [-1, 32, 14, 14]          9,632\n",
       "|    |    └─BatchNorm2d: 3-102           [-1, 32, 14, 14]          64\n",
       "|    |    └─ReLU: 3-103                  [-1, 32, 14, 14]          --\n",
       "|    |    └─Conv2d: 3-104                [-1, 32, 14, 14]          25,632\n",
       "|    |    └─BatchNorm2d: 3-105           [-1, 32, 14, 14]          64\n",
       "|    |    └─ReLU: 3-106                  [-1, 32, 14, 14]          --\n",
       "|    └─Sequential: 2-23                  [-1, 32, 14, 14]          --\n",
       "|    |    └─MaxPool2d: 3-107             [-1, 256, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-108                [-1, 32, 14, 14]          8,224\n",
       "|    |    └─BatchNorm2d: 3-109           [-1, 32, 14, 14]          64\n",
       "|    |    └─ReLU: 3-110                  [-1, 32, 14, 14]          --\n",
       "├─Inception: 1-8                         [-1, 264, 14, 14]         --\n",
       "|    └─Sequential: 2-24                  [-1, 56, 14, 14]          --\n",
       "|    |    └─Conv2d: 3-111                [-1, 56, 14, 14]          14,392\n",
       "|    |    └─BatchNorm2d: 3-112           [-1, 56, 14, 14]          112\n",
       "|    |    └─ReLU: 3-113                  [-1, 56, 14, 14]          --\n",
       "|    └─Sequential: 2-25                  [-1, 144, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-114                [-1, 72, 14, 14]          18,504\n",
       "|    |    └─BatchNorm2d: 3-115           [-1, 72, 14, 14]          144\n",
       "|    |    └─ReLU: 3-116                  [-1, 72, 14, 14]          --\n",
       "|    |    └─Conv2d: 3-117                [-1, 144, 14, 14]         259,344\n",
       "|    |    └─BatchNorm2d: 3-118           [-1, 144, 14, 14]         288\n",
       "|    |    └─ReLU: 3-119                  [-1, 144, 14, 14]         --\n",
       "|    └─Sequential: 2-26                  [-1, 32, 14, 14]          --\n",
       "|    |    └─Conv2d: 3-120                [-1, 16, 14, 14]          4,112\n",
       "|    |    └─BatchNorm2d: 3-121           [-1, 16, 14, 14]          32\n",
       "|    |    └─ReLU: 3-122                  [-1, 16, 14, 14]          --\n",
       "|    |    └─Conv2d: 3-123                [-1, 32, 14, 14]          12,832\n",
       "|    |    └─BatchNorm2d: 3-124           [-1, 32, 14, 14]          64\n",
       "|    |    └─ReLU: 3-125                  [-1, 32, 14, 14]          --\n",
       "|    |    └─Conv2d: 3-126                [-1, 32, 14, 14]          25,632\n",
       "|    |    └─BatchNorm2d: 3-127           [-1, 32, 14, 14]          64\n",
       "|    |    └─ReLU: 3-128                  [-1, 32, 14, 14]          --\n",
       "|    └─Sequential: 2-27                  [-1, 32, 14, 14]          --\n",
       "|    |    └─MaxPool2d: 3-129             [-1, 256, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-130                [-1, 32, 14, 14]          8,224\n",
       "|    |    └─BatchNorm2d: 3-131           [-1, 32, 14, 14]          64\n",
       "|    |    └─ReLU: 3-132                  [-1, 32, 14, 14]          --\n",
       "├─Inception: 1-9                         [-1, 416, 14, 14]         --\n",
       "|    └─Sequential: 2-28                  [-1, 128, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-133                [-1, 128, 14, 14]         33,920\n",
       "|    |    └─BatchNorm2d: 3-134           [-1, 128, 14, 14]         256\n",
       "|    |    └─ReLU: 3-135                  [-1, 128, 14, 14]         --\n",
       "|    └─Sequential: 2-29                  [-1, 160, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-136                [-1, 80, 14, 14]          21,200\n",
       "|    |    └─BatchNorm2d: 3-137           [-1, 80, 14, 14]          160\n",
       "|    |    └─ReLU: 3-138                  [-1, 80, 14, 14]          --\n",
       "|    |    └─Conv2d: 3-139                [-1, 160, 14, 14]         320,160\n",
       "|    |    └─BatchNorm2d: 3-140           [-1, 160, 14, 14]         320\n",
       "|    |    └─ReLU: 3-141                  [-1, 160, 14, 14]         --\n",
       "|    └─Sequential: 2-30                  [-1, 64, 14, 14]          --\n",
       "|    |    └─Conv2d: 3-142                [-1, 16, 14, 14]          4,240\n",
       "|    |    └─BatchNorm2d: 3-143           [-1, 16, 14, 14]          32\n",
       "|    |    └─ReLU: 3-144                  [-1, 16, 14, 14]          --\n",
       "|    |    └─Conv2d: 3-145                [-1, 64, 14, 14]          25,664\n",
       "|    |    └─BatchNorm2d: 3-146           [-1, 64, 14, 14]          128\n",
       "|    |    └─ReLU: 3-147                  [-1, 64, 14, 14]          --\n",
       "|    |    └─Conv2d: 3-148                [-1, 64, 14, 14]          102,464\n",
       "|    |    └─BatchNorm2d: 3-149           [-1, 64, 14, 14]          128\n",
       "|    |    └─ReLU: 3-150                  [-1, 64, 14, 14]          --\n",
       "|    └─Sequential: 2-31                  [-1, 64, 14, 14]          --\n",
       "|    |    └─MaxPool2d: 3-151             [-1, 264, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-152                [-1, 64, 14, 14]          16,960\n",
       "|    |    └─BatchNorm2d: 3-153           [-1, 64, 14, 14]          128\n",
       "|    |    └─ReLU: 3-154                  [-1, 64, 14, 14]          --\n",
       "├─MaxPool2d: 1-10                        [-1, 416, 6, 6]           --\n",
       "├─Inception: 1-11                        [-1, 416, 6, 6]           --\n",
       "|    └─Sequential: 2-32                  [-1, 128, 6, 6]           --\n",
       "|    |    └─Conv2d: 3-155                [-1, 128, 6, 6]           53,376\n",
       "|    |    └─BatchNorm2d: 3-156           [-1, 128, 6, 6]           256\n",
       "|    |    └─ReLU: 3-157                  [-1, 128, 6, 6]           --\n",
       "|    └─Sequential: 2-33                  [-1, 160, 6, 6]           --\n",
       "|    |    └─Conv2d: 3-158                [-1, 80, 6, 6]            33,360\n",
       "|    |    └─BatchNorm2d: 3-159           [-1, 80, 6, 6]            160\n",
       "|    |    └─ReLU: 3-160                  [-1, 80, 6, 6]            --\n",
       "|    |    └─Conv2d: 3-161                [-1, 160, 6, 6]           320,160\n",
       "|    |    └─BatchNorm2d: 3-162           [-1, 160, 6, 6]           320\n",
       "|    |    └─ReLU: 3-163                  [-1, 160, 6, 6]           --\n",
       "|    └─Sequential: 2-34                  [-1, 64, 6, 6]            --\n",
       "|    |    └─Conv2d: 3-164                [-1, 16, 6, 6]            6,672\n",
       "|    |    └─BatchNorm2d: 3-165           [-1, 16, 6, 6]            32\n",
       "|    |    └─ReLU: 3-166                  [-1, 16, 6, 6]            --\n",
       "|    |    └─Conv2d: 3-167                [-1, 64, 6, 6]            25,664\n",
       "|    |    └─BatchNorm2d: 3-168           [-1, 64, 6, 6]            128\n",
       "|    |    └─ReLU: 3-169                  [-1, 64, 6, 6]            --\n",
       "|    |    └─Conv2d: 3-170                [-1, 64, 6, 6]            102,464\n",
       "|    |    └─BatchNorm2d: 3-171           [-1, 64, 6, 6]            128\n",
       "|    |    └─ReLU: 3-172                  [-1, 64, 6, 6]            --\n",
       "|    └─Sequential: 2-35                  [-1, 64, 6, 6]            --\n",
       "|    |    └─MaxPool2d: 3-173             [-1, 416, 6, 6]           --\n",
       "|    |    └─Conv2d: 3-174                [-1, 64, 6, 6]            26,688\n",
       "|    |    └─BatchNorm2d: 3-175           [-1, 64, 6, 6]            128\n",
       "|    |    └─ReLU: 3-176                  [-1, 64, 6, 6]            --\n",
       "├─Inception: 1-12                        [-1, 512, 6, 6]           --\n",
       "|    └─Sequential: 2-36                  [-1, 192, 6, 6]           --\n",
       "|    |    └─Conv2d: 3-177                [-1, 192, 6, 6]           80,064\n",
       "|    |    └─BatchNorm2d: 3-178           [-1, 192, 6, 6]           384\n",
       "|    |    └─ReLU: 3-179                  [-1, 192, 6, 6]           --\n",
       "|    └─Sequential: 2-37                  [-1, 192, 6, 6]           --\n",
       "|    |    └─Conv2d: 3-180                [-1, 96, 6, 6]            40,032\n",
       "|    |    └─BatchNorm2d: 3-181           [-1, 96, 6, 6]            192\n",
       "|    |    └─ReLU: 3-182                  [-1, 96, 6, 6]            --\n",
       "|    |    └─Conv2d: 3-183                [-1, 192, 6, 6]           460,992\n",
       "|    |    └─BatchNorm2d: 3-184           [-1, 192, 6, 6]           384\n",
       "|    |    └─ReLU: 3-185                  [-1, 192, 6, 6]           --\n",
       "|    └─Sequential: 2-38                  [-1, 64, 6, 6]            --\n",
       "|    |    └─Conv2d: 3-186                [-1, 24, 6, 6]            10,008\n",
       "|    |    └─BatchNorm2d: 3-187           [-1, 24, 6, 6]            48\n",
       "|    |    └─ReLU: 3-188                  [-1, 24, 6, 6]            --\n",
       "|    |    └─Conv2d: 3-189                [-1, 64, 6, 6]            38,464\n",
       "|    |    └─BatchNorm2d: 3-190           [-1, 64, 6, 6]            128\n",
       "|    |    └─ReLU: 3-191                  [-1, 64, 6, 6]            --\n",
       "|    |    └─Conv2d: 3-192                [-1, 64, 6, 6]            102,464\n",
       "|    |    └─BatchNorm2d: 3-193           [-1, 64, 6, 6]            128\n",
       "|    |    └─ReLU: 3-194                  [-1, 64, 6, 6]            --\n",
       "|    └─Sequential: 2-39                  [-1, 64, 6, 6]            --\n",
       "|    |    └─MaxPool2d: 3-195             [-1, 416, 6, 6]           --\n",
       "|    |    └─Conv2d: 3-196                [-1, 64, 6, 6]            26,688\n",
       "|    |    └─BatchNorm2d: 3-197           [-1, 64, 6, 6]            128\n",
       "|    |    └─ReLU: 3-198                  [-1, 64, 6, 6]            --\n",
       "├─AvgPool2d: 1-13                        [-1, 512, 1, 1]           --\n",
       "├─Linear: 1-14                           [-1, 10]                  5,130\n",
       "==========================================================================================\n",
       "Total params: 3,799,530\n",
       "Trainable params: 3,799,530\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 787.61\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 16.85\n",
       "Params size (MB): 14.49\n",
       "Estimated Total Size (MB): 31.36\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(Google_net5, (3,32,32)) #expand below for the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84d49b04-a3ca-4630-9254-c59090df79a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# Training and testing functions\n",
    "def train(model, epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        progress_bar(batch_idx, len(trainloader), 'Train Loss: %.3f | Train Acc: %.3f%% (%d/%d)'\n",
    "                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "\n",
    "def test(model, epoch):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            progress_bar(batch_idx, len(testloader), 'Test Loss: %.3f | Test Acc: %.3f%% (%d/%d)'\n",
    "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.pth')\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa3156bc-5329-43b2-9b12-d66c185be31c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      " [================================================================>]  Step: 139ms | Tot: 1m23s | Train Loss: 1.464 | Train Acc: 46.222% (23111/5000 391/391 1  \n",
      "==> Time to complete training epoch:  84.27412939071655\n",
      " [================================================================>]  Step: 57ms | Tot: 5s817ms | Test Loss: 1.276 | Test Acc: 55.390% (5539/1000 100/100 \n",
      "==> Time to complete test epoch:  5.993894338607788\n",
      "\n",
      "Epoch: 1\n",
      " [================================================================>]  Step: 140ms | Tot: 1m23s | Train Loss: 0.954 | Train Acc: 66.354% (33177/5000 391/391 1  \n",
      "==> Time to complete training epoch:  83.85359740257263\n",
      " [================================================================>]  Step: 58ms | Tot: 5s796ms | Test Loss: 0.839 | Test Acc: 70.790% (7079/1000 100/100 \n",
      "==> Time to complete test epoch:  5.971439361572266\n",
      "\n",
      "Epoch: 2\n",
      " [================================================================>]  Step: 140ms | Tot: 1m23s | Train Loss: 0.730 | Train Acc: 74.670% (37335/5000 391/391 1  \n",
      "==> Time to complete training epoch:  83.94187808036804\n",
      " [================================================================>]  Step: 57ms | Tot: 5s812ms | Test Loss: 0.860 | Test Acc: 71.070% (7107/1000 100/100 \n",
      "==> Time to complete test epoch:  6.010834693908691\n",
      "\n",
      "Epoch: 3\n",
      " [================================================================>]  Step: 143ms | Tot: 1m24s | Train Loss: 0.594 | Train Acc: 79.594% (39797/5000 391/391 1  \n",
      "==> Time to complete training epoch:  84.56193137168884\n",
      " [================================================================>]  Step: 59ms | Tot: 5s885ms | Test Loss: 0.622 | Test Acc: 79.200% (7920/1000 100/100 \n",
      "==> Time to complete test epoch:  6.062749862670898\n",
      "\n",
      "Epoch: 4\n",
      " [================================================================>]  Step: 145ms | Tot: 1m25s | Train Loss: 0.509 | Train Acc: 82.280% (41140/5000 391/391 1  \n",
      "==> Time to complete training epoch:  86.34221506118774\n",
      " [================================================================>]  Step: 60ms | Tot: 6s30ms | Test Loss: 0.541 | Test Acc: 81.940% (8194/1000 100/100 \n",
      "==> Time to complete test epoch:  6.207306861877441\n",
      "\n",
      "Epoch: 5\n",
      " [================================================================>]  Step: 145ms | Tot: 1m26s | Train Loss: 0.444 | Train Acc: 84.730% (42365/5000 391/391 1  \n",
      "==> Time to complete training epoch:  86.80048203468323\n",
      " [================================================================>]  Step: 63ms | Tot: 6s2ms | Test Loss: 0.518 | Test Acc: 82.980% (8298/1000 100/100 \n",
      "==> Time to complete test epoch:  6.185855150222778\n",
      "\n",
      "Epoch: 6\n",
      " [================================================================>]  Step: 144ms | Tot: 1m26s | Train Loss: 0.402 | Train Acc: 85.998% (42999/5000 391/391 1  \n",
      "==> Time to complete training epoch:  86.72444152832031\n",
      " [================================================================>]  Step: 59ms | Tot: 5s995ms | Test Loss: 0.505 | Test Acc: 83.280% (8328/1000 100/100 \n",
      "==> Time to complete test epoch:  6.177858829498291\n",
      "\n",
      "Epoch: 7\n",
      " [================================================================>]  Step: 142ms | Tot: 1m26s | Train Loss: 0.355 | Train Acc: 87.870% (43935/5000 391/391 1  \n",
      "==> Time to complete training epoch:  86.6077036857605\n",
      " [================================================================>]  Step: 61ms | Tot: 5s998ms | Test Loss: 0.447 | Test Acc: 84.810% (8481/1000 100/100 \n",
      "==> Time to complete test epoch:  6.186498165130615\n",
      "\n",
      "Epoch: 8\n",
      " [================================================================>]  Step: 145ms | Tot: 1m26s | Train Loss: 0.326 | Train Acc: 88.792% (44396/5000 391/391 1  \n",
      "==> Time to complete training epoch:  86.5222806930542\n",
      " [================================================================>]  Step: 60ms | Tot: 5s990ms | Test Loss: 0.503 | Test Acc: 83.840% (8384/1000 100/100 \n",
      "==> Time to complete test epoch:  6.17714262008667\n",
      "\n",
      "Epoch: 9\n",
      " [================================================================>]  Step: 142ms | Tot: 1m26s | Train Loss: 0.294 | Train Acc: 89.816% (44908/5000 391/391 1  \n",
      "==> Time to complete training epoch:  86.44506573677063\n",
      " [================================================================>]  Step: 59ms | Tot: 5s978ms | Test Loss: 0.429 | Test Acc: 85.780% (8578/1000 100/100 \n",
      "==> Time to complete test epoch:  6.162711143493652\n",
      "\n",
      "Epoch: 10\n",
      " [================================================================>]  Step: 140ms | Tot: 1m25s | Train Loss: 0.267 | Train Acc: 90.736% (45368/5000 391/391 1  \n",
      "==> Time to complete training epoch:  85.70110130310059\n",
      " [================================================================>]  Step: 57ms | Tot: 5s815ms | Test Loss: 0.428 | Test Acc: 86.600% (8660/1000 100/100 .......................................................]  Step: 57ms | Tot: 61ms | Test Loss: 0.274 | Test Acc: 89.500% (179/20 2/100 \n",
      "Saving..\n",
      "==> Time to complete test epoch:  6.0619215965271\n",
      "\n",
      "Epoch: 11\n",
      " [================================================================>]  Step: 140ms | Tot: 1m23s | Train Loss: 0.246 | Train Acc: 91.470% (45735/5000 391/391 1  \n",
      "==> Time to complete training epoch:  83.9822142124176\n",
      " [================================================================>]  Step: 60ms | Tot: 5s783ms | Test Loss: 0.354 | Test Acc: 88.520% (8852/1000 100/100 \n",
      "Saving..\n",
      "==> Time to complete test epoch:  6.034530878067017\n",
      "\n",
      "Epoch: 12\n",
      " [================================================================>]  Step: 140ms | Tot: 1m23s | Train Loss: 0.226 | Train Acc: 92.186% (46093/5000 391/391 1  \n",
      "==> Time to complete training epoch:  84.05842590332031\n",
      " [================================================================>]  Step: 58ms | Tot: 5s835ms | Test Loss: 0.397 | Test Acc: 87.200% (8720/1000 100/100 \n",
      "==> Time to complete test epoch:  6.0198585987091064\n",
      "\n",
      "Epoch: 13\n",
      " [================================================================>]  Step: 138ms | Tot: 1m24s | Train Loss: 0.205 | Train Acc: 92.836% (46418/5000 391/391 1  \n",
      "==> Time to complete training epoch:  84.99655652046204\n",
      " [================================================================>]  Step: 59ms | Tot: 5s932ms | Test Loss: 0.398 | Test Acc: 87.240% (8724/1000 100/100 \n",
      "==> Time to complete test epoch:  6.109951972961426\n",
      "\n",
      "Epoch: 14\n",
      " [================================================================>]  Step: 145ms | Tot: 1m26s | Train Loss: 0.193 | Train Acc: 93.280% (46640/5000 391/391 1  \n",
      "==> Time to complete training epoch:  86.66350317001343\n",
      " [================================================================>]  Step: 60ms | Tot: 5s967ms | Test Loss: 0.392 | Test Acc: 87.820% (8782/1000 100/100 ......................................................]  Step: 58ms | Tot: 61ms | Test Loss: 0.229 | Test Acc: 92.000% (184/20 2/100 \n",
      "==> Time to complete test epoch:  6.142521142959595\n",
      "\n",
      "Epoch: 15\n",
      " [================================================================>]  Step: 139ms | Tot: 1m23s | Train Loss: 0.174 | Train Acc: 93.914% (46957/5000 391/391 1  \n",
      "==> Time to complete training epoch:  84.36594867706299\n",
      " [================================================================>]  Step: 56ms | Tot: 5s812ms | Test Loss: 0.405 | Test Acc: 87.900% (8790/1000 100/100 \n",
      "==> Time to complete test epoch:  5.993212938308716\n",
      "\n",
      "Epoch: 16\n",
      " [================================================================>]  Step: 140ms | Tot: 1m23s | Train Loss: 0.168 | Train Acc: 94.150% (47075/5000 391/391 1  \n",
      "==> Time to complete training epoch:  83.8514039516449\n",
      " [================================================================>]  Step: 56ms | Tot: 5s769ms | Test Loss: 0.369 | Test Acc: 88.880% (8888/1000 100/100 ..................................................]  Step: 62ms | Tot: 65ms | Test Loss: 0.306 | Test Acc: 90.000% (180/20 2/100 \n",
      "Saving..\n",
      "==> Time to complete test epoch:  6.014150381088257\n",
      "\n",
      "Epoch: 17\n",
      " [================================================================>]  Step: 140ms | Tot: 1m23s | Train Loss: 0.155 | Train Acc: 94.682% (47341/5000 391/391 1  \n",
      "==> Time to complete training epoch:  83.68612480163574\n",
      " [================================================================>]  Step: 62ms | Tot: 5s797ms | Test Loss: 0.390 | Test Acc: 88.240% (8824/1000 100/100 \n",
      "==> Time to complete test epoch:  5.983114004135132\n",
      "\n",
      "Epoch: 18\n",
      " [================================================================>]  Step: 140ms | Tot: 1m23s | Train Loss: 0.137 | Train Acc: 95.178% (47589/5000 391/391 1  \n",
      "==> Time to complete training epoch:  83.99474287033081\n",
      " [================================================================>]  Step: 58ms | Tot: 5s836ms | Test Loss: 0.377 | Test Acc: 89.100% (8910/1000 100/100 \n",
      "Saving..\n",
      "==> Time to complete test epoch:  6.079162836074829\n",
      "\n",
      "Epoch: 19\n",
      " [================================================================>]  Step: 147ms | Tot: 1m24s | Train Loss: 0.133 | Train Acc: 95.402% (47701/5000 391/391 1  \n",
      "==> Time to complete training epoch:  84.92691969871521\n",
      " [================================================================>]  Step: 58ms | Tot: 5s937ms | Test Loss: 0.373 | Test Acc: 89.070% (8907/1000 100/100 \n",
      "==> Time to complete test epoch:  6.119359254837036\n",
      "\n",
      "Epoch: 20\n",
      " [================================================================>]  Step: 146ms | Tot: 1m26s | Train Loss: 0.125 | Train Acc: 95.628% (47814/5000 391/391 1  \n",
      "==> Time to complete training epoch:  86.55080223083496\n",
      " [================================================================>]  Step: 57ms | Tot: 6s22ms | Test Loss: 0.394 | Test Acc: 88.820% (8882/1000 100/100 \n",
      "==> Time to complete test epoch:  6.205842971801758\n",
      "\n",
      "Epoch: 21\n",
      " [================================================================>]  Step: 144ms | Tot: 1m26s | Train Loss: 0.115 | Train Acc: 95.914% (47957/5000 391/391 1  \n",
      "==> Time to complete training epoch:  86.72572493553162\n",
      " [================================================================>]  Step: 60ms | Tot: 5s954ms | Test Loss: 0.401 | Test Acc: 88.980% (8898/1000 100/100 \n",
      "==> Time to complete test epoch:  6.140374660491943\n",
      "\n",
      "Epoch: 22\n",
      " [================================================================>]  Step: 144ms | Tot: 1m26s | Train Loss: 0.113 | Train Acc: 96.072% (48036/5000 391/391 1  \n",
      "==> Time to complete training epoch:  86.41100335121155\n",
      " [================================================================>]  Step: 58ms | Tot: 5s946ms | Test Loss: 0.373 | Test Acc: 89.420% (8942/1000 100/100 ................................]  Step: 61ms | Tot: 65ms | Test Loss: 0.307 | Test Acc: 89.500% (179/20 2/100 \n",
      "Saving..\n",
      "==> Time to complete test epoch:  6.186630725860596\n",
      "\n",
      "Epoch: 23\n",
      " [================================================================>]  Step: 144ms | Tot: 1m25s | Train Loss: 0.103 | Train Acc: 96.316% (48158/5000 391/391 1  \n",
      "==> Time to complete training epoch:  86.3526840209961\n",
      " [================================================================>]  Step: 58ms | Tot: 5s979ms | Test Loss: 0.419 | Test Acc: 88.460% (8846/1000 100/100 \n",
      "==> Time to complete test epoch:  6.176305770874023\n",
      "\n",
      "Epoch: 24\n",
      " [================================================================>]  Step: 145ms | Tot: 1m26s | Train Loss: 0.093 | Train Acc: 96.768% (48384/5000 391/391 1  \n",
      "==> Time to complete training epoch:  86.5328848361969\n",
      " [================================================================>]  Step: 59ms | Tot: 5s974ms | Test Loss: 0.401 | Test Acc: 89.130% (8913/1000 100/100 \n",
      "==> Time to complete test epoch:  6.165139436721802\n"
     ]
    }
   ],
   "source": [
    "# Conduct training and testing\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(Google_net5.parameters(), lr=0.05,\n",
    "                      momentum=0.9, weight_decay=5e-5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "for epoch in range(start_epoch, 25): #limit to 10 for highest efficiency\n",
    "    begin = time.time()\n",
    "    train(Google_net5, epoch)\n",
    "    print('==> Time to complete training epoch: ', time.time() - begin)\n",
    "    \n",
    "    test_begin = time.time()\n",
    "    test(Google_net5, epoch)\n",
    "    print('==> Time to complete test epoch: ', time.time() - test_begin)\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcb7ebe-58a4-4297-83bc-9db738b10685",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
